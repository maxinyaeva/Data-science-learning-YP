{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Отлично, что стоп-слова были исключены при векторизации!\n",
    "* Работа получилась отличной, тебе удалось добиться достаточно хорошего качества. Поздравляю!\n",
    "* Проект может быть зачтен, но я его отправлю назад, чтобы у тебя была возможность задать вопросы и внести правки, при желании. Однако, ты можешь просто вернуть проект в таком же виде и я его зачту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Прошу прощения за столь длительное молчание, честно скажу, что сейчас на меня много чего свалилось и с кандачка разобраться с пайпланом и бертом не получилось. Боюсь, что меня переведут в когорту младше, если не сдам проект в ближайшее время, поэтому прошу зачесть проект как есть, но я вернусь к твоим крутым ссылкам, когда станет по легче) выводы дописала. Еще раз спасибо за мнформацию, в тренажере почти ничего не понятно было))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 2)</font>\n",
    "* Проект зачтен!\n",
    "* Удачи в дальнейшем обучении и следующих работах!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет (ревью 2): </b> \n",
    "\n",
    "1. Внутри кросс-валидации происзодит разбиение переданной в нее выборку на части (треин и валидация). Подробнее тут: https://codecamp.ru/blog/cross-validation-k-fold/\n",
    "2. Мы хотим, чтобы при подборе параметров внутри кросс-валидации векторизатор не обучался на валидации. Для этого нам нужно его обучать каждый раз только на треине (внутри кросс-валидации). Для этого и нужен пайплайн, чтобы внутри кросс-валидации обучалась не только модель, но и векторизатор. \n",
    "\n",
    "Вот такой пайплайн нужно передать в кросс-валидацию:  \n",
    "`pipe_lr = Pipeline([(‘vect’, CountVectorizer()),\n",
    " (‘tfidf’, TfidfTransformer()),\n",
    " (‘model’, LogisticRegression())])`\n",
    "    \n",
    "Тут подробнее про то, как тюнить параметры у пайплайна: https://stackoverflow.com/questions/51606341/hyper-parameter-tuning-on-pipeline-object\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.8.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.5-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting plotly\n",
      "  Downloading plotly-5.7.0-py2.py3-none-any.whl (28.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting graphviz\n",
      "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from catboost) (1.8.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (4.31.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, graphviz, plotly, catboost\n",
      "Successfully installed catboost-1.0.5 graphviz-0.20 plotly-5.7.0 tenacity-8.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.11.0-cp39-cp39-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.4.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.2/763.2 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=e19adcd03b78b16eef3f05a587d7f0841f5791a7b702b4b8fd4a0f682e08af8b\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, regex, filelock, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.6.0 huggingface-hub-0.5.1 regex-2022.4.24 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем все необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим наш датасет и посмотрим на содержимое данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.info())\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим максимальное количество символов в строке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = data['text'].str.len().max()\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же необходимо посмотеть на сколько сбалансированы классы в целевом признаке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['toxic'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из диаграммы, классы не сбалансированны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы корректно работать с текстом, нам необходимо очистить текст от лишних символов и привести слова к основной форме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корректно, первичный осмотр проведен. Радует, что баланс классов был изучен.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим исходный файл на обучающу и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['toxic']\n",
    "features = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем данные к нужному типу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = features_train.values.astype('U')\n",
    "corpus_test = features_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Приводить тексты к юникоду не имеет смысла, так как они все на английском.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим в датасете только регулярные выражения. Воспользуемся методом re.sub(), применим его ко всему датасету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text_lem = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return text_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus_train)):\n",
    "    corpus_train[i] = clear_text(corpus_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus_test)):\n",
    "    corpus_test[i] = clear_text(corpus_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка была сделана верно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью стемминга приведем слова к форме основы. Воспользуемся инструментом EnglishStemmer из библиотеки nltk. Применим ко всему датасету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer(ignore_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.9 s, sys: 0 ns, total: 50.9 s\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(corpus_train)):\n",
    "    word_list = nltk.word_tokenize(corpus_train[i])\n",
    "    corpus_train[i] = ' '.join([stemmer.stem(w) for w in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.9 s, sys: 0 ns, total: 51.9 s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(corpus_test)):\n",
    "    word_list = nltk.word_tokenize(corpus_test[i])\n",
    "    corpus_test[i] = ' '.join([stemmer.stem(w) for w in word_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим базу стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем данные с учетом стоп-слов. Применим метод fit к обычающей выборке, а затем метод transform к обучающему и тестовому набору данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf = count_tf_idf.fit(corpus_train)\n",
    "train_x = tf_idf.transform(corpus_train)\n",
    "test_x = tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки (79785, 86919) (79785,)\n",
      "Размер тестовой выборки (79786, 86919) (79786,)\n"
     ]
    }
   ],
   "source": [
    "print('Размер обучающей выборки', train_x.shape, target_train.shape)\n",
    "print('Размер тестовой выборки', test_x.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы над этим пунктом мы получили две матрицы, готовые к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что векторизатор был обучен только на тренировочной части данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модели машинного обучения такие как: LogisticRegression, RandomForestClassifier, LGBMClassifier и CatBoostClassifier. Искомая метрика для определения лучшей модели - f1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем функцию для расчета метрики f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_f1(model, X_test, y_test):\n",
    "      \n",
    "    y_pred = pd.Series(model.predict(X_test))\n",
    "    \n",
    "    return f1_score(y_pred, y_test).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', random_state=12345,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=12345, solver = 'liblinear', class_weight='balanced')\n",
    "lr.fit(train_x, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.append(model_f1(lr, test_x, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хоть мы и добились желаемого результата, но можно постратаься улучшить метрику более сложными моделями машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим следующим классификатор RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs = { 'n_estimators': range (50, 200, 50),\n",
    "              'max_depth': range (1,25, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(rf, \n",
    "                    parametrs, \n",
    "                    cv=cv,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "CPU times: user 6min 12s, sys: 820 ms, total: 6min 13s\n",
      "Wall time: 6min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=12345, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight='balanced'),\n",
       "             param_grid={'max_depth': range(1, 25, 5),\n",
       "                         'n_estimators': range(50, 200, 50)},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(train_x, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.append(model_f1(grid.best_estimator_, test_x, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(boosting_type='gbdt',class_weight='balanced', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs = {\n",
    "    'learning_rate': np.logspace(-3, 0, 5),\n",
    "    'n_estimators': [100, 150],\n",
    "    'num_leaves': [21, 31, 41],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(lgbm, \n",
    "                    parametrs, \n",
    "                    cv=cv,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.799733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.641101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.637675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.639752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.612459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.641748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.769191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.786807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.816085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.785111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.650235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.649647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.812602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.659261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.662648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.684917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.667341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.672426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.668962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.907674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.678434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.749266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.735592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.732369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.752988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.862002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.746401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.984288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.624835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.778934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.725921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.740863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.759486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.800538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.859266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.767798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.706170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.724241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.683090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.714075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.947207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.802706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.352877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.196699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.782942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.836075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.887173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.246953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.887389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.118273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.882839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.747652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.799242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.148031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.992931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.366072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.010315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.140160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.325177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.610968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.031742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.071260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.005499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.970947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.909053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.854496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.028016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.118597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.925988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.855664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.898216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.922159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.856245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.973577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.401772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.859607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.850469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.838258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.073907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.855166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.355675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.473744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.503136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.925982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.291999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.131235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.041830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.071401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "CPU times: user 1h 14min 1s, sys: 11.4 s, total: 1h 14min 13s\n",
      "Wall time: 19min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=12345, shuffle=True),\n",
       "             estimator=LGBMClassifier(class_weight='balanced', verbose=0),\n",
       "             param_grid={'learning_rate': array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
       "                         'n_estimators': [100, 150],\n",
       "                         'num_leaves': [21, 31, 41]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(train_x, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.append(model_f1(grid.best_estimator_, test_x, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoostClassifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(task_type='GPU',\n",
    "                        eval_metric='TotalF1', \n",
    "                        od_type='Iter', \n",
    "                        od_wait=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs = {\n",
    "    'learning_rate': np.logspace(-3, 0, 5),\n",
    "    'iterations': [50, 100],\n",
    "    'depth': [6, 8, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(cb,\n",
    "                    parametrs,\n",
    "                    cv=cv,\n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid.fit(train_x, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.append(model_f1(grid.best_estimator_, test_x, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, мой компьютер не справился с расчетами и я сделала их на Google Colab  \n",
    "https://colab.research.google.com/drive/1WGBxR11BqJFiWZktlFJMJMaOTOf1e-p1#scrollTo=-VsARCTW4Y-1  \n",
    "Лучшие параметры модели: {'depth': 6, 'iterations': 100, 'learning_rate': 1.0}  \n",
    "f1 на тесте = 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.append('0.74')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем результаты в одну таблицу для наглядности и определим победителя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_result = pd.DataFrame(data=result,\n",
    "             index=['LogisticRegression', 'RandomForestClassifier', 'LGBMClassifier', 'CatBoostClassifier'],\n",
    "             columns=['f1_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       f1_score\n",
       "LogisticRegression         0.75\n",
       "RandomForestClassifier      0.4\n",
       "LGBMClassifier             0.74\n",
       "CatBoostClassifier         0.74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однозначным лидером для решения данной задачи является LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что попробовал разные модели в этом шаге!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В проекте были рассмотрены 4 модели машинного обучения и лучшей оказалась самая простая модель LogisticRegression.  \n",
    "На практике анализ текста оказался сложнее, чем можно себе представить. Мощности рабочего компьютера может не хватать для развертывания более сложных моделей машинного обучения. Тут не маловажную часть занимает время отработки кода. Логистическая регрессия показала себя прекрасно по скорости обучения (доли секунд), но искомая метрика равная 0.75 не является пределом совершенства. К тому же классы в значительной степени не сбалансированы в таргете.  \n",
    "В будущем, постараюсь разобраться со специализированными моделями ML, которые помогут делать более качественный прогноз классификации текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Финальный вывод желательно было сделать подробнее.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
